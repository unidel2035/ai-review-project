llm:
  provider: OLLAMA
  meta:
    model: codellama:7b
    max_tokens: 4000
    temperature: 0.3
  http_client:
    timeout: 120
    api_url: http://localhost:11434

vcs:
  provider: GITHUB
  http_client:
    timeout: 120
    api_url: https://api.github.com
    api_token: "${GITHUB_TOKEN}"  # Используем переменную окружения

  pipeline:
    owner: "unidel2035"
    repo: "ai-review-project"
    pull_number: "1"

logging:
  level: INFO
  format: json
